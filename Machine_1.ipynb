{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question :- What are the three stages to build the hypotheses or model in machine learning?\n",
    "Answere  :- Three Stages are below :- \n",
    "         #   1. Model Buliding (Step:- Preprocessing , Data wrangling etc)\n",
    "         #   2. Model Testing  (Step:- Testing accuracy, auc, etc. )\n",
    "         #   3. Model Implementation or apply the Model (Step :- Prediticing the new data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question:- What is the standard approach to supervised learning?\n",
    "\n",
    "Answere :- Below are some basic approach:-\n",
    "        \n",
    "        1. The standard approach to supervised learning is to split the set of example into the training set and the test.\n",
    "        2. EDA on Data set \n",
    "        3. Preprocessing of Data (Missing values etc)\n",
    "        4. Apply different algo to measure the accuracy and error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question:- What is Training set and Test set ?\n",
    "\n",
    "Answere :- This come when we are dealing with Supervisied data set. \n",
    "        1. Training Set is part of Data Set. On which Algorithim learn the pattern towards the Target Value.\n",
    "        2. Test Set is also part of Data Set, On which machine test the model towards given target value.\n",
    "        Standard partion of Data is 80% Training Set and 20% Test Set.\n",
    "        Note:-  Data must be suffled prior apply partion.\n",
    "       \n",
    "       A Training Set is a dataset used to train a model. In training the model, specific features are picked out from the training set. These features are then incorporated into the model.\n",
    "\n",
    "The Test Set is a dataset used to measure how well the model performs at making predictions on that test set.\n",
    "If the prediction scores for the test set are unreasonable, weâ€™ll have to make some adjustments to our model\n",
    "and try again.\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question:- What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?\n",
    "\n",
    "Answere :- Boosting and bagging are similar, in that they are both ensembling techniques, where a number of weak learners (classifiers/regressors that are barely better than guessing) combine (through averaging or max vote) to create a strong learner that can make accurate predictions. Bagging means that you take bootstrap samples (with replacement) of your data set and each sample trains a (potentially) weak learner. Boosting, on the other hand, uses all data to train each learner, but instances that were misclassified by the previous learners are given more weight so that subsequent learners give more focus to them during training.\n",
    "\n",
    "Bagging builds multiple base models with re-sampled training data with replacement. We train base classifiers on different samples of training data. Using random subsets of the data to train base models promotes more differences between the base models.\n",
    "\n",
    "Boosting is another ensemble technique to create a collection of predictors. In this technique, learners are learned sequentially with early learners fitting simple models to the data and then analyzing data for errors. In other words, we fit consecutive trees (random sample) and at every step, the goal is to solve for net error from the prior tree.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question:- How can you avoid overfitting ?\n",
    "\n",
    "Answere :- Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. \n",
    "there are many ways few ways which i know:-\n",
    "        1. Collect More Data\n",
    "        2. use ensembling methods that \"average\" models\n",
    "        3. choose simpler models / penalize complexity\n",
    "        4. The classic way to avoid overfitting is to divide your data sets into three groups -- a training set, a test set, and a validation set. You find the coefficients using the training set; you find the best form of the equation using the test set, test for over-fitting using the validation set.\n",
    "        Identify the important variables and think about the model that you are likely to specify, then plan ahead to collect a sample large enough handle all predictors, interactions, and polynomial terms your response variable might require\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
